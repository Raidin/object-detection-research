{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import xmltodict\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Oxfold Pet Dataset\n",
    "ROOT_DIR = os.path.abspath('./')\n",
    "DATA_ROOT = os.path.abspath('./data/Oxford_Pet_Dataset')\n",
    "ANN_DIR = os.path.join(DATA_ROOT, 'annotations/xmls')\n",
    "IMG_DIR = os.path.join(DATA_ROOT, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jihunjung/Oxford-IIIT_dataset\n",
      "\u001b[01;34m.\u001b[00m\n",
      "├── \u001b[01;34mannotations\u001b[00m\n",
      "│   ├── \u001b[01;34mtrimaps\u001b[00m [7390 entries exceeds filelimit, not opening dir]\n",
      "│   ├── \u001b[01;34mxmls\u001b[00m [3686 entries exceeds filelimit, not opening dir]\n",
      "│   ├── README\n",
      "│   ├── list.txt\n",
      "│   ├── test.txt\n",
      "│   └── trainval.txt\n",
      "├── \u001b[01;34mimages\u001b[00m [7393 entries exceeds filelimit, not opening dir]\n",
      "├── \u001b[01;31mannotations.tar.gz\u001b[00m\n",
      "└── \u001b[01;31mimages.tar.gz\u001b[00m\n",
      "\n",
      "4 directories, 6 files\n",
      "/home/jihunjung/deeplearning_research/research_note/object_detection/RCNN\n"
     ]
    }
   ],
   "source": [
    "# Display Dataset Structure\n",
    "%cd $DATA_ROOT\n",
    "!tree --dirsfirst --filelimit 10\n",
    "%cd $ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Catetory :: 37\n",
      "Abyssinian\n",
      "Bengal\n",
      "Birman\n",
      "Bombay\n",
      "British Shorthair\n",
      "Egyptian Mau\n",
      "Maine Coon\n",
      "Persian\n",
      "Ragdoll\n",
      "Russian Blue\n",
      "Siamese\n",
      "Sphynx\n",
      "american bulldog\n",
      "american pit bull terrier\n",
      "basset hound\n",
      "beagle\n",
      "boxer\n",
      "chihuahua\n",
      "english cocker spaniel\n",
      "english setter\n",
      "german shorthaired\n",
      "great pyrenees\n",
      "havanese\n",
      "japanese chin\n",
      "keeshond\n",
      "leonberger\n",
      "miniature pinscher\n",
      "newfoundland\n",
      "pomeranian\n",
      "pug\n",
      "saint bernard\n",
      "samoyed\n",
      "scottish terrier\n",
      "shiba inu\n",
      "staffordshire bull terrier\n",
      "wheaten terrier\n",
      "yorkshire terrier\n"
     ]
    }
   ],
   "source": [
    "# Display Overal Category\n",
    "img_list = os.listdir(IMG_DIR)\n",
    "img_list = [os.path.splitext(x)[0] for x in img_list]\n",
    "img_list = [\" \".join(re.findall(\"[a-zA-Z]+\", x)) for x in img_list]\n",
    "categories = list(sorted(set(img_list)))\n",
    "print('Total Catetory :: {}'.format(len(categories)))\n",
    "print('\\n'.join(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('abyssinian', 99)\n",
      "('bengal', 98)\n",
      "('birman', 100)\n",
      "('bombay', 100)\n",
      "('british_shorthair', 100)\n",
      "('egyptian_mau', 92)\n",
      "('maine_coon', 100)\n",
      "('persian', 100)\n",
      "('ragdoll', 99)\n",
      "('russian_blue', 100)\n",
      "('siamese', 100)\n",
      "('sphynx', 100)\n",
      "('american_bulldog', 100)\n",
      "('american_pit_bull_terrier', 100)\n",
      "('basset_hound', 100)\n",
      "('beagle', 100)\n",
      "('boxer', 100)\n",
      "('chihuahua', 100)\n",
      "('english_cocker_spaniel', 100)\n",
      "('english_setter', 100)\n",
      "('german_shorthaired', 100)\n",
      "('great_pyrenees', 100)\n",
      "('havanese', 100)\n",
      "('japanese_chin', 100)\n",
      "('keeshond', 100)\n",
      "('leonberger', 100)\n",
      "('miniature_pinscher', 100)\n",
      "('newfoundland', 100)\n",
      "('pomeranian', 100)\n",
      "('pug', 100)\n",
      "('saint_bernard', 99)\n",
      "('samoyed', 99)\n",
      "('scottish_terrier', 100)\n",
      "('shiba_inu', 100)\n",
      "('staffordshire_bull_terrier', 100)\n",
      "('wheaten_terrier', 100)\n",
      "('yorkshire_terrier', 100)\n"
     ]
    }
   ],
   "source": [
    "class_names = dict()\n",
    "\n",
    "# Annotation Parsing\n",
    "xmls = sorted(os.listdir(ANN_DIR))\n",
    "for i, xml in enumerate(xmls):\n",
    "    ann =  xmltodict.parse(open(os.path.join(ANN_DIR, xml), 'rb'))['annotation']\n",
    "    filename = ann['filename']\n",
    "\n",
    "    basename = os.path.splitext(filename)[0]\n",
    "    class_name = basename[:basename.rfind(\"_\")].lower()\n",
    "\n",
    "    if class_name not in class_names:\n",
    "        class_names[class_name] = 1\n",
    "    else:\n",
    "        class_names[class_name] += 1\n",
    "\n",
    "for i in class_names.items():\n",
    "    print(i)\n",
    "\n",
    "# preserve percentage of samples for each class (\"stratified\")\n",
    "# output.sort(key=lambda tup : tup[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-deeplearning",
   "language": "python",
   "name": "deeplearning_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
