{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1 Region Proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import patches\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NWPU-RESISC45 Air Plane Dataset\n",
    "ROOT_DIR = os.path.abspath('../')\n",
    "DATA_ROOT = os.path.abspath('./data/air_planes')\n",
    "ANN_DIR = os.path.join(DATA_ROOT, 'annotations/')\n",
    "IMG_DIR = os.path.join(DATA_ROOT, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApplySelectiveSearch(img):\n",
    "    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "    ss.setBaseImage(img)\n",
    "    ss.switchToSelectiveSearchFast()\n",
    "    ssresults = ss.process()\n",
    "    #print('Proposed Region :: {}'.format(len(ssresults)))\n",
    "    \n",
    "    # ssresults의 bbow 좌표 포맷 x, y, w, h\n",
    "    # 현재 코드에서 사용되는 bbox 좌표 포맷은 xmin, ymin, xmax, ymax\n",
    "    # IOU 계산 및  DrawBox 함수 모듈화를 위해 convert\n",
    "    ssresults[:, 2] = ssresults[:, 0] + ssresults[:, 2]\n",
    "    ssresults[:, 3] = ssresults[:, 1] + ssresults[:, 3]\n",
    "        \n",
    "    return ssresults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawBox(img, bboxes, title='Empty', color='magenta', ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "    \n",
    "    # BBox Display\n",
    "    # Box 좌표 구성(xmin, ymin, xmax, ymax)\n",
    "    for bbox in bboxes:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        p = patches.Rectangle((x1, y1), (x2-x1), (y2-y1), linewidth=2, alpha=1.0, linestyle=\"solid\", edgecolor=color, facecolor='none')\n",
    "        ax.add_patch(p)\n",
    "\n",
    "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetGroundTruthBBox(ann):\n",
    "    # Air_Plane Dataset Annotation Data Pasing\n",
    "    gt_bbox = np.array([], dtype=np.int32).reshape(0, 4)\n",
    "    for row in ann.iterrows():\n",
    "        line = row[1][0].split(\" \")\n",
    "        x1 = int(line[0])\n",
    "        y1 = int(line[1])\n",
    "        x2 = int(line[2])\n",
    "        y2 = int(line[3])\n",
    "        gt_bbox = np.vstack([gt_bbox, [x1, y1, x2, y2]])\n",
    "    \n",
    "    return gt_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute IOU between Ground Truth & Proposed Region\n",
    "'''\n",
    "@params\n",
    "  - gt : ground truth bounding box (4,)\n",
    "  - p : proposed region bounding box (n, 4)\n",
    "'''\n",
    "def ComputeIOU(gt, p):\n",
    "\n",
    "    x1 = np.maximum(gt[0], p[:, 0])\n",
    "    y1 = np.maximum(gt[1], p[:, 1])\n",
    "    x2 = np.minimum(gt[2], p[:, 2])\n",
    "    y2 = np.minimum(gt[3], p[:, 3])\n",
    "\n",
    "    intersection = np.maximum(x2 - x1, 0) * np.maximum(y2 - y1, 0)\n",
    "    gt_area = (gt[2] - gt[0]) * (gt[3] - gt[1])\n",
    "    propoesed_area = (p[:, 2] - p[:, 0]) * (p[:, 3] - p[:, 1])\n",
    "    union = gt_area + propoesed_area[:] - intersection[:]\n",
    "\n",
    "    iou = intersection/union\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Delta value between Ground Truth & Proposed Region\n",
    "'''\n",
    "@params\n",
    "  - gt : ground truth bounding box (4,)\n",
    "  - p : proposed region bounding box (n, 4)\n",
    "'''\n",
    "def ComputeTargetDelta(gt, p):\n",
    "    d = np.zeros_like(p, dtype=np.float32)\n",
    "    gt = gt.astype(np.float32)\n",
    "    p = p.astype(np.float32)\n",
    "\n",
    "    d[:, 0] = np.divide(np.subtract(gt[0], p[:,0]), p[:,2])\n",
    "    d[:, 1] = np.divide(np.subtract(gt[1], p[:,1]), p[:,3])\n",
    "    d[:, 2] = np.log(np.divide(gt[2], p[:,2]))\n",
    "    d[:, 3] = np.log(np.divide(gt[2], p[:,3]))\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WarppingImage(img, regions, delta):\n",
    "    cls_trn_img = np.array([], dtype=np.uint8).reshape(0, 224, 224, 3)\n",
    "    cls_trn_lb = np.array([], dtype=np.int32).reshape(0, 1)\n",
    "    reg_trn_img = np.array([], dtype=np.uint8).reshape(0, 224, 224, 3)\n",
    "    reg_trn_delta = np.array([], dtype=np.float32).reshape(0, 4)\n",
    "    cnt = 0\n",
    "    \n",
    "    for region in regions:\n",
    "        label, x1, y1, x2, y2 = region\n",
    "        \n",
    "        # 원본영상에서 region 영역 crop\n",
    "        timg = img[y1:y2, x1:x2]\n",
    "        # 224x224 크기로 wrapping\n",
    "        rimg = cv2.resize(timg, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        # img file 그룹화 하기 위해서 dim 추가\n",
    "        rimg = np.expand_dims(rimg, axis=0)\n",
    "        \n",
    "        cls_trn_img = np.vstack([cls_trn_img, rimg])\n",
    "        cls_trn_lb = np.vstack([cls_trn_lb, label])\n",
    "        \n",
    "        if label == 1:\n",
    "            reg_trn_img = np.vstack([reg_trn_img, rimg])\n",
    "            reg_trn_delta = np.vstack([reg_trn_delta, delta[cnt]])\n",
    "            cnt += 1\n",
    "    return cls_trn_img, cls_trn_lb, reg_trn_img, reg_trn_delta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdjustRegion(gt_bboxes, roi):\n",
    "    POS_LB = 1\n",
    "    NEG_LB = 0\n",
    "    MAX_COUNT = 30\n",
    "    regions = np.array([], dtype=np.int32).reshape(0, 5)\n",
    "    delta = np.array([], dtype=np.float32).reshape(0, 4)\n",
    "    \n",
    "    for bbox in gt_bboxes:\n",
    "        iou_results = ComputeIOU(bbox, roi)\n",
    "        # selective search로 얻은 region은 최대 2000개 까지만 사용\n",
    "        iou_results = iou_results[:2000]\n",
    "\n",
    "        # i'th GT BBox와 IOU가 0.5 이상인 경우 Positive(최대 영역 갯수 30개)\n",
    "        if len(regions[np.where(regions[:,0] == POS_LB)]) < MAX_COUNT:\n",
    "            temp_pos = roi[np.where(iou_results >= 0.5)]\n",
    "            if len(temp_pos) > MAX_COUNT:\n",
    "                temp_pos = temp_pos[:MAX_COUNT]\n",
    "                \n",
    "            # Positive 영역과 GT간의 Delta값 계산\n",
    "            delta = np.vstack([delta, ComputeTargetDelta(bbox, temp_pos)])\n",
    "            \n",
    "            # 0번째 index에 positive label insert\n",
    "            pos = np.insert(temp_pos, 0, POS_LB, axis=1)\n",
    "            regions = np.vstack([regions, pos])\n",
    "\n",
    "        # i'th GT BBox와 IOU가 0.5 이상인 경우 Negative(최대 영역 갯수 30개)\n",
    "        if len(regions[np.where(regions[:,0] == NEG_LB)]) < MAX_COUNT:\n",
    "            temp_neg = roi[np.where(iou_results <= 0.3)]\n",
    "            if len(temp_neg) > MAX_COUNT:\n",
    "                temp_neg = temp_neg[:MAX_COUNT]\n",
    "            \n",
    "            # 0번째 index에 negative label insert\n",
    "            temp_neg = np.insert(temp_neg, 0, NEG_LB, axis=1)\n",
    "            regions = np.vstack([regions, temp_neg])\n",
    "          \n",
    "    return regions, delta\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.path.join(DATA_ROOT, IMG_DIR)\n",
    "ann_path = os.path.join(DATA_ROOT, ANN_DIR)\n",
    "img_files = sorted(os.listdir(img_path))\n",
    "\n",
    "cls_trn_img = np.array([], dtype=np.uint8).reshape(0, 224, 224, 3)\n",
    "cls_trn_lb = np.array([], dtype=np.int32).reshape(0, 1)\n",
    "reg_trn_img = np.array([], dtype=np.uint8).reshape(0, 224, 224, 3)\n",
    "reg_trn_delta = np.array([], dtype=np.float32).reshape(0, 4)\n",
    "\n",
    "is_visible_sample = False\n",
    "\n",
    "# Annotation File Read\n",
    "for img_file in tqdm(img_files):\n",
    "    print(img_file)\n",
    "    # 1. image file load\n",
    "    ann_file = '{}.csv'.format(os.path.splitext(img_file)[0])\n",
    "    img = cv2.imread(os.path.join(img_path, img_file))\n",
    "\n",
    "    #2. To Obtain positive and negative region\n",
    "    ## 2-1. Apply Selective Search and obtain ROI\n",
    "    roi = ApplySelectiveSearch(img)\n",
    "\n",
    "    ## 2-2. Get Ground Truth Bounding Box Info\n",
    "    ann = pd.read_csv(os.path.join(ann_path, ann_file))\n",
    "    gt_bboxes = GetGroundTruthBBox(ann)\n",
    "\n",
    "    ## 2-3. Generate Train Region to Compute IOU Between GT BBox and ROI\n",
    "    regions, delta = AdjustRegion(gt_bboxes, roi)\n",
    "\n",
    "    ## 2-3. Warpping Image\n",
    "    _cls_trn_img, _cls_trn_lb, _reg_trn_img, _reg_trn_delta = WarppingImage(img, regions, delta)\n",
    "    cls_trn_img = np.vstack([cls_trn_img, _cls_trn_img])\n",
    "    cls_trn_lb = np.vstack([cls_trn_lb, _cls_trn_lb])\n",
    "    reg_trn_img = np.vstack([reg_trn_img, _reg_trn_img])\n",
    "    reg_trn_delta = np.vstack([reg_trn_delta, _reg_trn_delta])\n",
    "    \n",
    "#     if i == 0 and is_visible_sample:\n",
    "#         _, ax = plt.subplots(2, 2, figsize=(20, 20))\n",
    "#         DrawBox(img, gt_bboxes, title='GT', ax=ax[0][0])\n",
    "#         DrawBox(img, roi, title='ROI', color='red', ax=ax[0][1])\n",
    "#         DrawBox(img, pos, title='pos', color='blue', ax=ax[1][0])\n",
    "#         DrawBox(img, neg, title='neg', color='cyan', ax=ax[1][1])\n",
    "\n",
    "#         plt.tight_layout()\n",
    "\n",
    "# Save Train DATA\n",
    "np.savez_compressed('train_data.npz', cls_trn_img=cls_trn_img, cls_trn_lb=cls_trn_lb, reg_trn_img=reg_trn_img, reg_trn_delta=reg_trn_delta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stpe-2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Train Data(with regions)\n",
    "# train_data = np.load('train_data.npz')\n",
    "\n",
    "val_split = 0.2\n",
    "\n",
    "cls_trn_img = train_data['cls_trn_img']\n",
    "cls_trn_lb = to_categorical(train_data['cls_trn_lb'], 2)\n",
    "\n",
    "total = cls_trn_img.shape[0]\n",
    "num_val = int(total * val_split)\n",
    "num_train = total - num_val\n",
    "\n",
    "print('num of validation ::',num_val)\n",
    "print('num of train ::', num_train)\n",
    "\n",
    "# shuffle all data\n",
    "indexes = np.arange(total)\n",
    "np.random.shuffle(indexes)\n",
    "train_x = cls_trn_img[num_val:]\n",
    "train_y = cls_trn_lb[num_val:]\n",
    "val_x = cls_trn_img[:num_val]\n",
    "val_y = cls_trn_lb[:num_val]\n",
    "\n",
    "print('train shape::', train_x.shape, train_y.shape)\n",
    "print('val shape::', val_x.shape, val_y.shape)\n",
    "\n",
    "# Data Augmentation\n",
    "# train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "# train_datagen.fit(cls_trn_img)\n",
    "\n",
    "# # train-data\n",
    "# train_generator = train_datagen.flow(cls_trn_img, cls_trn_lb, batch_size=32, shuffle=True, subset='training')\n",
    "# print(train_generator)\n",
    "# # val-data\n",
    "# validation_generator = train_datagen.flow(cls_trn_img, cls_trn_lb, batch_size=32, shuffle=True, subset='validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras import Model\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "vggmodel = VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "for layers in (vggmodel.layers)[:15]:\n",
    "    layers.trainable = False\n",
    "    \n",
    "X = vggmodel.layers[-2].output\n",
    "predictions = Dense(2, activation=\"softmax\")(X)\n",
    "\n",
    "model_final = Model(input = vggmodel.input, output = predictions)\n",
    "opt = Adam(lr=0.0001)\n",
    "model_final.compile(loss = keras.losses.categorical_crossentropy, optimizer = opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
